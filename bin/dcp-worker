#!/usr/bin/env node
/**
 *  @file       dcp-worker.js
 *              Standalone NodeJS DCP Worker
 *
 *  @author     Ryan Rossiter, ryan@kingsds.network
 *  @date       April 2020
 */
'use strict';

const process = require('process');
const os = require('os');
const fs = require('fs');
const path = require('path');

const TOTAL_CPU_VCORES = os.cpus().length;
const DEFAULT_CORES = TOTAL_CPU_VCORES - 1;
var worker, dcpConfig;

const EXIT_UNHANDLED = 5;

/* Setup the telnet REPL up early to ensure early-failure log messages are captured */
const replHelpers = {
  help: {
    report: 'Print a worker status & slice report',
    kill: 'Try to kill the worker',
    die:  'Kill the worker',
  },
  commands: {
    report: printReport,
    kill:   process.exit,
    die:    () => worker && worker.stop()
  },
};
require('../lib/remote-console').init(replHelpers);

require('dcp-client').init({ configName: process.env.DCP_CONFIG || '../etc/dcp-worker-config' })
  .then(main)
  .catch(handleUnhandled);

async function main ()
{
  var defaultPidFileName = require('../lib/pidfile').getDefaultPidFileName(dcpConfig.worker.pidfile);
  
  process.on('SIGINT', handleSigDeath);
  process.on('SIGTERM', handleSigDeath);
  process.on('SIGQUIT', handleSigDeath);
  process.on('unhandledRejection', handleUnhandled);
  process.on('uncaughtException', handleUnhandled);

  dcpConfig = require('dcp/dcp-config');
  
  const cliArgs = require('dcp/cli')
  .base('Standalone NodeJS DCP Worker')
    .options({
      paymentAddress: {
        describe: 'The address to deposit funds into, will use the default bank keystore if not provided.',
        type: 'string',
      },
      cores: {
        alias: 'c',
        describe: 'Number of cores to work with',
        type: 'number',
        default: DEFAULT_CORES,
      },
      verbose: {
        alias: 'v',
        describe: 'Enable verbose output',
        type: 'count',
        default: false,
        group: 'Output options',
      },
      outputMode: {
        alias: ['o', 'output'],
        describe: 'Set the output mode',
        type: 'string',
        default: 'detect',
        choices: ['detect', 'console', 'dashboard', 'event-log', 'syslog', 'logfile'],
        group: 'Output options',
      },
      hostname: {
        alias: 'H',
        describe: 'Evaluator hostname',
        type: 'string',
        default: dcpConfig.evaluator.location.hostname,
      },
      port: {
        alias: 'p',
        describe: 'Evaluator port',
        type: 'number',
        default: Number(dcpConfig.evaluator.location.port),
      },
      priorityOnly: {
        alias: 'P',
        describe: 'Set the priority mode [deprecated]',
        type: 'boolean',
        default: false
      },
      'job-id': {
        alias: 'j',
        describe: 'Restrict worker to a specific job (use N times for N jobs)',
        type: 'array',
      },

      join: {
        alias: 'g',
        describe: 'Join compute group; the format is "joinKey,joinSecret" or "joinKey,eh1-joinHash"',
        type: 'array'
      },
      joinKeystore: {
        hidden: true,
        /* future */
      },

      leavePublicGroup: {
        type: 'boolean',
        describe: 'Do not fetch slices from public compute group',
        default: false,
      },
      publicGroupFallback: {
        describe: 'If set, worker will prefer private groups but fall back on the public group if no preferred work is available',
        type: 'boolean',
        default: false,
      },

      identityKey: {
        describe: 'Identity key, in hex format',
        type: 'string',
        group: 'Identity options',
      },
      identityKeystore: {
        describe: 'Identity keystore, in json format',
        type: 'string',
        group: 'Identity options',
      },

      reportInterval: {
        describe: 'If set, output a status summary every [interval] seconds in console output mode',
        type: 'number',
        group: 'Output options',
      },
      eventDebug: {
        hide: true,
        describe: 'If set, dump all sandbox and worker events',
      },

      logfile: {
        describe: 'Path to log file (if --output=file)',
        type: 'string',
        group: 'Log File output options',
      },
      syslogAddress: {
        describe: 'Address of rsyslog server (if --output=syslog)',
        type: 'string',
        group: 'Syslog output options',
      },
      syslogTransport: {
        describe: 'Transport to connect to rsyslog daemon (if --output=syslog)',
        type: 'string',
        choices: ['udp','tcp'],
        group: 'Syslog output options',
      },
      syslogPort: {
        describe: 'UDP/TCP port of rsyslog server',
        type: 'number',
        group: 'Syslog output options',
      },

      allowedOrigins: {
        alias: 'a',
        describe: 'modify the \'any\' allow origins of dcpConfig',
        type: 'array'
      },

      watchdogInterval: {
        alias: 'W',
        describe: 'Number of milliseconds between watchdog cycles',
        type: 'number',
        hidden: true,
      },
      dumpConfig: {
        describe: 'If set, dump the configuration and exit',
        type: 'boolean',
        hidden: true,
      },
      pidFile: {
        alias: 'f',
        describe: `create a .pid file for the worker; value overrides default location (${defaultPidFileName})`,
        normalize: true
      },
    })
  .strict()
  .wrap(process.stdout.columns || 80)
  .argv;

  if (cliArgs.dumpConfig)
  {
    console.debug(JSON.stringify(require('dcp/dcp-config'), null, 2));
    process.exit(0);
  }

  await startWorking(cliArgs);
}


// Imperfect, but handles CG { joinKey, joinHash }.
function isHash(b) {
  return b && b.length === 68 && b.startsWith('eh1-');
}

async function startWorking(cliArgs) {
  const wallet = require('dcp/wallet');
  const DCPWorker = require('dcp/worker').Worker;
  const { startWorkerLogger } = require('../lib/startWorkerLogger');
  const sawOptions = {
    hostname: cliArgs.hostname,
    port:     cliArgs.port
  };

  let paymentAddress = false
      || cliArgs.paymentAddress
      || dcpConfig.worker.paymentAddress
      || (await wallet.get()).address;

  if (typeof paymentAddress === 'string')
    paymentAddress = new wallet.Address(paymentAddress);
    
  if (cliArgs.pidFile)
    require('../lib/pidfile').write(cliArgs.pidFile)

  // Different ways to get the identity: 
  let identityKeystore = false;

  if (cliArgs.identityKey)
    identityKeystore = await new wallet.IdKeystore(cliArgs.identityKey, '');
  else if (cliArgs.identityKeystore)
    identityKeystore = await new wallet.IdKeystore(JSON.parse(cliArgs.identityKeystore), '');
  else
    identityKeystore = await wallet.getId();

  // Set the provided identity as the wallet's default
  await wallet.addId(identityKeystore);

  // Leave the public compute group, if desired
  if (cliArgs.leavePublicGroup || cliArgs.publicGroupFallback)
    dcpConfig.worker.leavePublicGroup = true;

  /** @type {string[]} */
  const dcpWorkerOptions = dcpConfig.worker;

  Object.assign(dcpWorkerOptions, {
    paymentAddress,
    maxWorkingSandboxes: cliArgs.cores,
    cores:               { cpu: TOTAL_CPU_VCORES, gpu: undefined }, /** XXXpfr @todo: Figure out how many gpus. */
    targetLoad:          { cpu: 1.0, gpu: 1.0 }, /** Use 100%: XXXpfr @todo Allow command-line override. */
    sandboxOptions: {
      SandboxConstructor: require('dcp-client/lib/standaloneWorker').workerFactory(sawOptions)
    },
    computeGroups: [], /* public group is implied */
    leavePublicGroup: cliArgs.leavePublicGroup || dcpConfig.worker.leavePublicGroup,
  });

  /* cliArgs.join is the list of compute groups to join */
  if (cliArgs.join && cliArgs.join.length)
  {
    dcpWorkerOptions.computeGroups = cliArgs.join
      .map((el) => {
        /* Map cliArgs.join to give us [{ joinKey, joinSecret/joinHash }...] */
        const [a, b] = el.split(',');
        return isHash(b) ? { joinKey: a, joinHash: b } : { joinKey: a, joinSecret: b };
      })
      .filter((el) => el.joinKey); /* Filter out entries with no joinKey */
    //console.log(dcpWorkerOptions.computeGroups);
  }
  
  if (cliArgs.jobId)
  {
    dcpWorkerOptions.jobAddresses = cliArgs.jobId;
    dcpWorkerOptions.priorityOnly = true;
  }
  if (cliArgs.allowedOrigins)
    dcpConfig.worker.allowOrigins.any.push(...cliArgs.allowedOrigins);
  if (cliArgs.watchdogInterval)
    dcpWorkerOptions.watchdogInterval = cliArgs.watchdogInterval;

  worker = new DCPWorker(identityKeystore, dcpWorkerOptions);
  worker.on('error', console.error);

  /* Let incorrect event-loop references keep us alive when linked with a debug library, but
   * exit quickly/accurately for production code even when the library isn't perfect.
   */
  if (require('dcp/build').config.build !== 'debug')
    worker.on('end', process.exit);
  else
    worker.on('end', () => setTimeout(process.exit, Number(dcpConfig.worker.cleanupTimeout || "60") * 1000).unref());

  /**
   * NOTE: In Supervisor2 this function is a NOOP.
   * When (and if) we stop using Supevisor1, delete this reference to setDefaultIdentityKeystore
   * and delete the corresponding fucntion from Supervisor2.
   *
   * startWorkerLogger needs to be called before the worker is started so that
   * it can attach event listeners before the events fire, else UI events for
   * things such as progress will never get attached.
   *
   * setDefaultIdentityKeystore needs to be called before the logger because it
   * tries access the identity of the worker before it has started, i.e. where
   * it sets its identity, throwing an assertion error.
   *
   * FIXME(bryan-hoang): This is a fragile solution that is too coupled with the
   * implementation of the worker that should be addressed in Supervisor 2
   */
  await worker.supervisor.setDefaultIdentityKeystore();

  if (cliArgs.eventDebug)
  {
    worker.debug = true;
    worker.supervisor.debug = true;
  }

  worker.on('stop', () => { console.log('Worker is stopping') });
  worker.on('end',  () => { logClosing('log', 'Worker has stopped') });
  startWorkerLogger(worker, cliArgs);

  require('../lib/remote-console').setMainEval(function mainEval() { return eval(arguments[0]) });

  let introBanner = '';
  introBanner += ` * Starting DCP Worker` + '\n';
  introBanner += ` . Configured for scheduler ${dcpConfig.scheduler.location}` + '\n';
  introBanner += ` . Bank is ${dcpConfig.bank.location}` + '\n';
  introBanner += ` . Earned funds will be deposited in account ${paymentAddress}` + '\n';
  introBanner += ` . Identity is ${identityKeystore.address}` + '\n';

  function qty(amount, singular, plural) /* XXX i18n */
  {
    if (Array.isArray(amount))
      amount = amount.length;
    if (!plural)
      plural = singular + 's';
    if (!amount)
      return plural;
    if (amount == 1)
      return singular;
    return plural;
  }

  if (dcpWorkerOptions.jobAddresses)
    introBanner += ` * Processing only ${qty(dcpWorkerOptions.jobAddresses, 'job')} ` + dcpWorkerOptions.jobAddresses.join(', ') + '\n';
  if (dcpWorkerOptions.computeGroups.length)
    introBanner += ` * Joining compute ${qty(dcpWorkerOptions.computeGroups, 'group')} ` + dcpWorkerOptions.computeGroups.map(el => el.joinKey).join(', ') + '\n';
  if (dcpWorkerOptions.publicGroupFallback)
    introBanner += ' * Falling back on public group when preferred groups have no work' + '\n';
  else if (dcpWorkerOptions.leavePublicGroup)
    introBanner += ' * Leaving the public compute group' + '\n';
  if (cliArgs.verbose)
    introBanner += ` + Verbosity level: ${cliArgs.verbose}` + '\n';
  if (cliArgs.eventDebug)
    introBanner += ' + Event debug on' + '\n';
  introBanner += ' . output mode: ' + cliArgs.outputMode + '\n';
  
  introBanner += ' . ready' + '\n';

  console.log(introBanner);

  require('../lib/check-scheduler-version').check();

  /**
   *  Convert a timespan in ms to a human-readable interval in minutes and seconds
   *
   *  @param  {number} el Milliseconds to convert
   *  @return {string}    Timespan formatted as `m:ss`
   */
  function toInterval(el)
  {
    const m = Math.floor((el / 1000) / 60).toString(10);
    const s = Math.floor((el / 1000) % 60).toString(10).padStart(2, '0');
    return `${m}:${s}`;
  }

  if (parseFloat(cliArgs.reportInterval))
  {
    if (cliArgs.outputMode !== 'dashboard')
      setInterval(printReport, parseFloat(cliArgs.reportInterval) * 1000);
    else
      console.log('Ignoring --reportInterval in dashboard output mode');
  }


  /* Start the worker. Normal process exit happens by virtue of the worker<end> event */
  await worker.start();
}

/**
 * Log a closing message (or messages). Since the dashboard clears the screen on exit, we use the
 * memoized console property to log the message after we destroy the instance of screen.
 */
function logClosing(facility, ...message) 
{
  var screen = require('../lib/worker-loggers/dashboard').screen;

  if (!screen)
    console[facility](message);
  else
  {
    /* Turn off TUI and resume "normal" console logging.
     * FUTURE: dashboard API should know how to unregister its hook.
     */
    screen.log(...message);
    screen.destroy();
    screen = false;
    console = new (require('console').Console)(process);
    require('../lib/remote-console').reintercept();
    console[facility](...message);
  }
}

/** 
 * Fatal error handler: __must not ever throw no matter what__.
 * If we hit a fatal error, we are by definition no longer confident of our program state, meaning that
 * the worker must be restarted. This handler does its best to report the rejection and give the worker a few
 * seconds in which to attempt to return slices to the scheduler before it gives up completely.
 */
async function handleUnhandled(error)
{
  var _worker = worker;
  worker = false;

  process.exitCode = process.exitCode || EXIT_UNHANDLED;
  
  try
  {
    logClosing(error);
  } catch(e) {};

  if (!_worker)
    console.error('trapped unhandled error:', error)
  else
  {
    console.error('trapped unhandled error -- stopping worker:', error);
    _worker.on('end', process.exit);
    _worker.stop();
  }

  const cleanupTimer = setTimeout(() => {
    logClosing('error', 'handleFatalError timeout - exiting now');
    process.exit();
  }, Number(dcpConfig.worker.cleanupTimeout || "60") * 1000).unref();
  
  try {
    let log = dcpConfig && dcpConfig.worker && dcpConfig.worker.unhandledRejectionLog;
    if (!log) log = process.env.DCP_WORKER_UNHANDLED_REJECTION_LOG;
    if (log) {
      fs.appendFileSync(process.env.DCP_WORKER_UNHANDLED_REJECTION_LOG,
                        `${Date.now()}: ${error.message}\n${error.stack}\n\n`);
    }
  } catch(e) {};
}

/** print the slice report via console.log */
function printReport()
{
  console.log(sliceReport());
}

/** retrieve a slice report screen */
function sliceReport()
{
  const sup = worker.supervisor;
  let report = '';

  report += ('='.repeat(78)) + '\n';

  const sbStates = {
    WORKING: 0,
    ASSIGNED: 0,
    READY: 0,
    TERMINATED: 0,
  };
  const stateNames = {
    WORKING: 'Working',
    ASSIGNED: 'Assigned',
    READY: 'Ready',
    TERMINATED: 'Terminated',
  };
  sup.sandboxes.forEach(sb => {
    const { state } = sb;
    if (!sbStates[state])
      sbStates[state] = 0;
    sbStates[state]++;
  });

  report += (Date()) + '\n';
  report += ('Sandboxes:') + '\n';
  Object.keys(sbStates).forEach(state => {
    const stateName = stateNames[state] || state;
    report += (`  ${(stateName + ':').padEnd(12)} ${sbStates[state]}`) + '\n';
  })
  report += (`  * ALL:       ${sup.sandboxes.length}`) + '\n';

  report += ('Progress:') + '\n';
  sup.workingSandboxes.forEach(sb => {
    const jobName = sb.job && sb.job.public && sb.job.public.name || `idek (${sb.jobAddress})`;
    let el = Date.now() - sb.sliceStartTime;
    const t = el < 1000000
          ? toInterval(el)
          : 'new';

    el = sb.progressReports && sb.progressReports.last
      ? Date.now() - (sb.sliceStartTime + sb.progressReports.last.timestamp)
      : 0;
    const pct = (typeof sb.progress) === 'number'
          ? `${Number(sb.progress).toFixed(0).padStart(2)}%`
          : 'ind';
    const stale = (el < 2000) ? '' : `(stale: ${toInterval(el)})`;

    report += (` ${String(sb.id).padStart(4)}: ${sb.jobAddress} ${jobName.padEnd(34)} `+ `${t} ${pct} ${stale}`.padStart(13)) + '\n';
  });

  report += ('Slices:') + '\n';
  report += (`  working:     ${sup.allocatedSlices.length}`) + '\n';
  report += (`  queued:      ${sup.queuedSlices.length}`) + '\n';

  report += ('='.repeat(78)) + '\n';

  return report;
}

/**
 * Handle a signal which requests our the death of the Worker by 
 *  - stopping the worker
 *  - unregistering the handler (this allows a second signal to forcibly terminate the process
 *    if that is the default behaviour)
 *  - set a long timeout (dcpConfig.worker.cleanupTimeout seconds), after which the process
 *    exits forcibly with a non-zero exit code (unix standard for various signals)
 */
function handleSigDeath(signalName, signal)
{
  process.off(signalName, handleSigDeath);

  if (!worker)
    console.error(`trapped ${signalName}, signal ${signal}`);
  else
  {
    console.error(`trapped ${signalName}, signal ${signal} -- stopping worker`);
    worker.stop();
  }

  const cleanupTimer = setTimeout(() => process.exit(signal - 128),
                                  Number(dcpConfig.worker.cleanupTimeout || "60") * 1000).unref();
}

